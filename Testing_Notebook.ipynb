{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import transformers\n",
    "import sentence_transformers\n",
    "import faiss\n",
    "import archs4py\n",
    "import pandas as pd\n",
    "import re\n",
    "import json\n",
    "\n",
    "archive_file = \"human_gene_v2.5.h5\"\n",
    "\n",
    "def remove_non_alphanumeric(strings):\n",
    "    # Define a regular expression pattern to match non-alphanumeric characters\n",
    "    pattern = r'[^a-zA-Z0-9]'\n",
    "    \n",
    "    # Use a list comprehension to apply the regex substitution to each string\n",
    "    cleaned_strings = [re.sub(pattern, '', s) for s in strings]\n",
    "    \n",
    "    return cleaned_strings\n",
    "\n",
    "def split_and_retain_quoted(strings):\n",
    "\n",
    "    # Regular expression to match quoted strings or words\n",
    "    pattern = r'\"[^\"]*\"|\\S+'\n",
    "    \n",
    "    # Find all matches in the text\n",
    "    matches = re.findall(pattern, strings)\n",
    "    clean_matches = [element for element in matches if element.startswith('\"') and element.endswith('\"')]\n",
    "    clean_matches = [element[1:-1] for element in clean_matches]\n",
    "    \n",
    "    return clean_matches\n",
    "\n",
    "def get_config_data():\n",
    "    with open(\"local_data.json\") as json_file:\n",
    "        data = json.load(json_file)\n",
    "        return data[\"OPENAI_KEY\"][\"key\"]\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "#file_path = archs4py.download.counts(\"human\", path=\"\", version=\"latest\")\n",
    "\n",
    "def handle_archs4py_query(query, file, selection_type):\n",
    "\n",
    "    \"\"\"\n",
    "    Accepts a parsed user query and filters the dataset using archs4py.\n",
    "    \n",
    "    Parameters:\n",
    "    - query: str, the user query\n",
    "    - file: the loaded dataset\n",
    "    - selection_type: str, the type of selection to perform (samples, series, or terms)\n",
    "    \n",
    "    Returns:\n",
    "    - query_dataset: a subset of the dataset relevant to the query that consists of a list of data objects (e.g. meta and RNAseq data)\n",
    "    \"\"\"\n",
    "    try:\n",
    "        if selection_type == \"samples\":\n",
    "            temp_meta = archs4py.meta.samples(file, query, \n",
    "                meta_fields=[\"geo_accession\", \"series_id\", \"characteristics_ch1\", \"extract_protocol_ch1\", \"source_name_ch1\", \"title\"])\n",
    "            #temp_data = archs4py.data.samples(file, query)\n",
    "            #matched_samples = [col for col in temp_meta.index if col in temp_data.columns]\n",
    "            #temp_data = temp_data[matched_samples]\n",
    "            #temp_meta = temp_meta.loc[matched_samples]\n",
    "            #query_dataset = {'meta': temp_meta, 'RNAseq': temp_data}\n",
    "            query_dataset = {'meta': temp_meta}\n",
    "        elif selection_type == \"series\":\n",
    "            temp_meta = archs4py.meta.series(file, query, \n",
    "                meta_fields=[\"geo_accession\", \"series_id\", \"characteristics_ch1\", \"extract_protocol_ch1\", \"source_name_ch1\", \"title\"])\n",
    "            #temp_data = archs4py.data.series(file, query)\n",
    "            #matched_samples = [col for col in temp_meta.index if col in temp_data.columns]\n",
    "            #temp_data = temp_data[matched_samples]\n",
    "            #temp_meta = temp_meta.loc[matched_samples]\n",
    "            #query_dataset = {'meta': temp_meta, 'RNAseq': temp_data}\n",
    "            query_dataset = {'meta': temp_meta}\n",
    "        elif selection_type == \"terms\":\n",
    "            temp_meta = archs4py.meta.meta(file, query, \n",
    "                meta_fields=[\"geo_accession\", \"series_id\", \"characteristics_ch1\", \"extract_protocol_ch1\", \"source_name_ch1\", \"title\"], \n",
    "                remove_sc=True)\n",
    "            #temp_samples = temp_meta[\"geo_accession\"]\n",
    "            #temp_data = archs4py.data.samples(file, temp_samples)\n",
    "            #matched_samples = [col for col in temp_meta.index if col in temp_data.columns]\n",
    "            #temp_data = temp_data[matched_samples]\n",
    "            #temp_meta = temp_meta.loc[matched_samples]\n",
    "            #query_dataset = {'meta': temp_meta, 'RNAseq': temp_data}\n",
    "            query_dataset = {'meta': temp_meta}\n",
    "        else:\n",
    "            raise ValueError(\"Invalid selection type. Please choose 'sample', 'series', or 'term'.\")\n",
    "        return query_dataset\n",
    "    \n",
    "    except Exception as e:\n",
    "        return f\"Error retrieving data: {str(e)}\"\n",
    "\n",
    "def parse_archs4py_query(full_query):\n",
    "    \"\"\"\n",
    "    Parses a user query into chunks suitable for the handle_archs4py_query function.\n",
    "    \n",
    "    Parameters:\n",
    "    - full_query: str, the unfiltereduser query\n",
    "    \n",
    "    Returns:\n",
    "    - query_dataset: a subset of the dataset relevant to the full query that consists of a list of data objects (e.g. meta and RNAseq data)\n",
    "    \"\"\"\n",
    "    try:\n",
    "        # Convert the query to uppercase to ensure case-insensitive matching\n",
    "        \n",
    "        if \"GSM\" in full_query:\n",
    "            query_upper = full_query.upper()\n",
    "            # Perform operation for queries containing \"GSM\"\n",
    "            # Split the string into a list of elements using spaces as the separator\n",
    "            temp_elements = query_upper.split()\n",
    "            temp_elements = remove_non_alphanumeric(temp_elements)\n",
    "        \n",
    "            # Filter the list to include only elements containing \"GSE\"\n",
    "            temp_samples = [temp_element for temp_element in temp_elements if \"GSM\" in temp_element]\n",
    "\n",
    "            # Select data for the samples\n",
    "            return handle_archs4py_query(temp_samples, archive_file, \"samples\")\n",
    "\n",
    "        elif \"GSE\" in full_query:\n",
    "            query_upper = full_query.upper()\n",
    "            # Perform operation for queries containing \"GSE\"\n",
    "            # Split the string into a list of elements using spaces as the separator\n",
    "            temp_elements = query_upper.split()\n",
    "            temp_elements = remove_non_alphanumeric(temp_elements)\n",
    "        \n",
    "            # Filter the list to include only elements containing \"GSE\"\n",
    "            temp_series = [temp_element for temp_element in temp_elements if \"GSE\" in temp_element]\n",
    "\n",
    "            if len(temp_series) > 1:\n",
    "                prior_dataset = []\n",
    "            for temp_index, temp_value in enumerate(temp_series):\n",
    "                temp_dataset = handle_archs4py_query(temp_value, archive_file, \"series\")\n",
    "                if temp_index > 0:\n",
    "                    temp_dataset['meta'] = pd.concat([prior_dataset['meta'], \n",
    "                                                    temp_dataset['meta']], \n",
    "                                                    ignore_index=True)\n",
    "                if temp_index < len(temp_series) - 1:\n",
    "                    prior_dataset = temp_dataset\n",
    "            return temp_dataset\n",
    "\n",
    "        else:\n",
    "            # Perform default operation for other queries\n",
    "            temp_terms = split_and_retain_quoted(full_query)\n",
    "            print(temp_terms)\n",
    "            if len(temp_terms) > 1:\n",
    "                prior_dataset = []\n",
    "            for temp_index, temp_value in enumerate(temp_terms):\n",
    "                print(temp_value)\n",
    "                temp_dataset = handle_archs4py_query(temp_value, archive_file, \"terms\")\n",
    "                print(temp_dataset['meta'].shape)\n",
    "                if temp_index > 0:\n",
    "                    temp_dataset['meta'] = temp_dataset['meta'][temp_dataset['meta'].index.isin(prior_dataset['meta'].index)]\n",
    "                    print(temp_dataset['meta'].shape)\n",
    "                if temp_index < len(temp_terms) - 1:\n",
    "                    prior_dataset = temp_dataset\n",
    "            return temp_dataset\n",
    "\n",
    "    except Exception as e:\n",
    "        return f\"Error retrieving data: {str(e)}\"\n",
    "\n",
    "\n",
    "def get_archs4py_expression_counts(query, file):\n",
    "\n",
    "    \"\"\"\n",
    "    Accepts a parsed user query and filters the dataset using archs4py.\n",
    "    \n",
    "    Parameters:\n",
    "    - query: str, the user query\n",
    "    - file: the loaded dataset\n",
    "    \n",
    "    Returns:\n",
    "    - temp_data: a subset of the dataset relevant to the query that consists of a list of data objects (e.g. meta and RNAseq data)\n",
    "    \"\"\"\n",
    "    try:\n",
    "        temp_data = archs4py.data.samples(file, query)\n",
    "        return temp_data\n",
    "\n",
    "    except Exception as e:\n",
    "        return f\"Error retrieving data: {str(e)}\"\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(5, 6)\n",
      "           geo_accession          series_id  \\\n",
      "GSM1132425    GSM1132425           GSE46562   \n",
      "GSM1132426    GSM1132426           GSE46562   \n",
      "GSM1132427    GSM1132427           GSE46562   \n",
      "GSM1179927    GSM1179927  GSE43526,GSE43900   \n",
      "GSM1179928    GSM1179928  GSE43526,GSE43900   \n",
      "\n",
      "                                          characteristics_ch1  \\\n",
      "GSM1132425       SAMPLE GROUP: CONTROL,TISSUE: 14 DAY NEURONS   \n",
      "GSM1132426       SAMPLE GROUP: CONTROL,TISSUE: 14 DAY NEURONS   \n",
      "GSM1132427       SAMPLE GROUP: CONTROL,TISSUE: 14 DAY NEURONS   \n",
      "GSM1179927  CELL TYPE: FOREBRAIN CORTICAL NEURONS,AGENT: V...   \n",
      "GSM1179928  CELL TYPE: FOREBRAIN CORTICAL NEURONS,AGENT: T...   \n",
      "\n",
      "                                         extract_protocol_ch1  \\\n",
      "GSM1132425  RNA-SEQ WAS CARRIED OUT ON AND DAY 14 NEURONS ...   \n",
      "GSM1132426  RNA-SEQ WAS CARRIED OUT ON AND DAY 14 NEURONS ...   \n",
      "GSM1132427  RNA-SEQ WAS CARRIED OUT ON AND DAY 14 NEURONS ...   \n",
      "GSM1179927  RNA WAS EXTRACTED USING TRIZOL REAGENT.,SRANDE...   \n",
      "GSM1179928  RNA WAS EXTRACTED USING TRIZOL REAGENT.,SRANDE...   \n",
      "\n",
      "                                              source_name_ch1  \\\n",
      "GSM1132425                                    CONTROL NEURONS   \n",
      "GSM1132426                                    CONTROL NEURONS   \n",
      "GSM1132427                                    CONTROL NEURONS   \n",
      "GSM1179927  IPSCS WERE DIFFERENTIATED INTO FOREBRAIN CORTI...   \n",
      "GSM1179928  IPSCS WERE DIFFERENTIATED INTO FOREBRAIN CORTI...   \n",
      "\n",
      "                               title  \n",
      "GSM1132425                     IPSC5  \n",
      "GSM1132426                     IPSC6  \n",
      "GSM1132427                     IPSC2  \n",
      "GSM1179927    VEHICLE_RNASEQ [HUMAN]  \n",
      "GSM1179928  TOPOTECAN_RNASEQ [HUMAN]  \n",
      "geo_accession\n",
      "GSM1132425    1\n",
      "GSM1132426    1\n",
      "GSM1132427    1\n",
      "GSM1179927    1\n",
      "GSM1179928    1\n",
      "Name: count, dtype: int64\n",
      "series_id\n",
      "GSE46562             3\n",
      "GSE43526,GSE43900    2\n",
      "Name: count, dtype: int64\n",
      "characteristics_ch1\n",
      "SAMPLE GROUP: CONTROL,TISSUE: 14 DAY NEURONS              3\n",
      "CELL TYPE: FOREBRAIN CORTICAL NEURONS,AGENT: VEHICLE      1\n",
      "CELL TYPE: FOREBRAIN CORTICAL NEURONS,AGENT: TOPOTECAN    1\n",
      "Name: count, dtype: int64\n",
      "extract_protocol_ch1\n",
      "RNA-SEQ WAS CARRIED OUT ON AND DAY 14 NEURONS AT THE COLUMBIA GENOME CENTER. TOTAL RNA WAS ISOLATED FROM CELLS USING THE MIRNEASY KIT (QIAGEN) ACCORDING TO THE MANUFACTURERÂS PROTOCOL. AN ADDITIONAL DNASE1 DIGESTION STEP WAS PERFORMED TO ENSURE THAT THE SAMPLES WERE NOT CONTAMINATED WITH GENOMIC DNA. RNA PURITY WAS ASSESSED USING THE AGILANT 2100 BIOANALYZER (BEIJING GENOMICS INSTITUTE). EACH RNA SAMPLE HAD AN A260:A280 RATIO ABOVE 1.8, A RIN>9, AND A A260:A230 RATIO ABOVE 2.2.,BRIEFLY, TOTAL RNA WAS CONVERTED TO CDNA USING OLIGO DT, WHICH WAS THEN USED FOR ILLUMINA SEQUENCING LIBRARY PREPARATION.    3\n",
      "RNA WAS EXTRACTED USING TRIZOL REAGENT.,SRANDED LIBRARIES WERE CONSTRUCTED WITH ILLUMINA KITS FOR STRANDED RNASEQ.                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                2\n",
      "Name: count, dtype: int64\n",
      "source_name_ch1\n",
      "CONTROL NEURONS                                                                                           3\n",
      "IPSCS WERE DIFFERENTIATED INTO FOREBRAIN CORTICAL NEURONS AND TREATED WITH VEHICLE FOR 6 DAYS.            1\n",
      "IPSCS WERE DIFFERENTIATED INTO FOREBRAIN CORTICAL NEURONS AND TREATED WITH 10ÂΜM TOPOTECAN FOR 6 DAYS.    1\n",
      "Name: count, dtype: int64\n",
      "title\n",
      "IPSC5                       1\n",
      "IPSC6                       1\n",
      "IPSC2                       1\n",
      "VEHICLE_RNASEQ [HUMAN]      1\n",
      "TOPOTECAN_RNASEQ [HUMAN]    1\n",
      "Name: count, dtype: int64\n"
     ]
    }
   ],
   "source": [
    "\n",
    "#test1 = parse_archs4py_query('I want to look up data for the \"iPSC\" and \"neuro\" samples')\n",
    "test1 = parse_archs4py_query('I want to look up data for GSM1132425, GSM1132426, GSM1132427, GSM1179927, and GSM1179928')\n",
    "print(test1['meta'].shape)\n",
    "print(test1['meta'].head())\n",
    "print(test1['meta']['geo_accession'].value_counts())\n",
    "print(test1['meta']['series_id'].value_counts())\n",
    "print(test1['meta']['characteristics_ch1'].value_counts())\n",
    "print(test1['meta']['extract_protocol_ch1'].value_counts())\n",
    "print(test1['meta']['source_name_ch1'].value_counts())\n",
    "print(test1['meta']['title'].value_counts())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 5/5 [00:01<00:00,  2.54it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(67186, 5)\n",
      "          GSM1132425  GSM1132426  GSM1132427  GSM1179927  GSM1179928\n",
      "TSPAN6          1561        3554        1046       10111       11536\n",
      "TNMD             174         832           8          31          21\n",
      "DPM1            1057        2367         575        4349        4022\n",
      "SCYL3            574        1017         374        1713        2168\n",
      "C1orf112         427         641         170         624         665\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "\n",
    "###Load counts for selected samples\n",
    "temp_samples = test1['meta']['geo_accession'].tolist()\n",
    "temp_data = get_archs4py_expression_counts(temp_samples, archive_file)\n",
    "print(temp_data.shape)\n",
    "print(temp_data.head())\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [],
   "source": [
    "OPENAI_API_KEY = get_config_data()\n",
    "\n",
    "import nest_asyncio\n",
    "\n",
    "nest_asyncio.apply()\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "\u001b[1m> Entering new AgentExecutor chain...\u001b[0m\n",
      "\u001b[32;1m\u001b[1;3m\n",
      "Invoking: `python_repl_ast` with `{'query': 'len(df)'}`\n",
      "\n",
      "\n",
      "\u001b[0m\u001b[36;1m\u001b[1;3m5\u001b[0m\u001b[32;1m\u001b[1;3mThere are 5 rows in the dataframe `df`.\u001b[0m\n",
      "\n",
      "\u001b[1m> Finished chain.\u001b[0m\n",
      "\n",
      "\n",
      "\u001b[1m> Entering new AgentExecutor chain...\u001b[0m\n",
      "\u001b[32;1m\u001b[1;3m\n",
      "Invoking: `python_repl_ast` with `{'query': 'df.info()'}`\n",
      "\n",
      "\n",
      "\u001b[0m\u001b[36;1m\u001b[1;3m<class 'pandas.core.frame.DataFrame'>\n",
      "Index: 5 entries, GSM1132425 to GSM1179928\n",
      "Data columns (total 6 columns):\n",
      " #   Column                Non-Null Count  Dtype \n",
      "---  ------                --------------  ----- \n",
      " 0   geo_accession         5 non-null      object\n",
      " 1   series_id             5 non-null      object\n",
      " 2   characteristics_ch1   5 non-null      object\n",
      " 3   extract_protocol_ch1  5 non-null      object\n",
      " 4   source_name_ch1       5 non-null      object\n",
      " 5   title                 5 non-null      object\n",
      "dtypes: object(6)\n",
      "memory usage: 280.0+ bytes\n",
      "\u001b[0m\u001b[32;1m\u001b[1;3mThe main properties of the data in the dataframe `df` are as follows:\n",
      "\n",
      "- **Index**: The dataframe has an index with 5 entries, ranging from `GSM1132425` to `GSM1179928`.\n",
      "- **Columns**: There are a total of 6 columns:\n",
      "  1. `geo_accession`: Contains 5 non-null entries of type `object`.\n",
      "  2. `series_id`: Contains 5 non-null entries of type `object`.\n",
      "  3. `characteristics_ch1`: Contains 5 non-null entries of type `object`.\n",
      "  4. `extract_protocol_ch1`: Contains 5 non-null entries of type `object`.\n",
      "  5. `source_name_ch1`: Contains 5 non-null entries of type `object`.\n",
      "  6. `title`: Contains 5 non-null entries of type `object`.\n",
      "- **Data Types**: All columns are of type `object`.\n",
      "- **Memory Usage**: The dataframe uses approximately 280.0 bytes of memory.\n",
      "\n",
      "Overall, the dataframe contains complete data with no missing values across all columns.\u001b[0m\n",
      "\n",
      "\u001b[1m> Finished chain.\u001b[0m\n",
      "\n",
      "\n",
      "\u001b[1m> Entering new AgentExecutor chain...\u001b[0m\n",
      "\u001b[32;1m\u001b[1;3m\n",
      "Invoking: `python_repl_ast` with `{'query': \"summary = df.groupby(['characteristics_ch1', 'extract_protocol_ch1', 'title', 'source_name_ch1']).size().reset_index(name='count')\\nsummary\"}`\n",
      "\n",
      "\n",
      "\u001b[0m\u001b[36;1m\u001b[1;3m                                 characteristics_ch1  \\\n",
      "0  CELL TYPE: FOREBRAIN CORTICAL NEURONS,AGENT: T...   \n",
      "1  CELL TYPE: FOREBRAIN CORTICAL NEURONS,AGENT: V...   \n",
      "2       SAMPLE GROUP: CONTROL,TISSUE: 14 DAY NEURONS   \n",
      "3       SAMPLE GROUP: CONTROL,TISSUE: 14 DAY NEURONS   \n",
      "4       SAMPLE GROUP: CONTROL,TISSUE: 14 DAY NEURONS   \n",
      "\n",
      "                                extract_protocol_ch1  \\\n",
      "0  RNA WAS EXTRACTED USING TRIZOL REAGENT.,SRANDE...   \n",
      "1  RNA WAS EXTRACTED USING TRIZOL REAGENT.,SRANDE...   \n",
      "2  RNA-SEQ WAS CARRIED OUT ON AND DAY 14 NEURONS ...   \n",
      "3  RNA-SEQ WAS CARRIED OUT ON AND DAY 14 NEURONS ...   \n",
      "4  RNA-SEQ WAS CARRIED OUT ON AND DAY 14 NEURONS ...   \n",
      "\n",
      "                      title  \\\n",
      "0  TOPOTECAN_RNASEQ [HUMAN]   \n",
      "1    VEHICLE_RNASEQ [HUMAN]   \n",
      "2                     IPSC2   \n",
      "3                     IPSC5   \n",
      "4                     IPSC6   \n",
      "\n",
      "                                     source_name_ch1  count  \n",
      "0  IPSCS WERE DIFFERENTIATED INTO FOREBRAIN CORTI...      1  \n",
      "1  IPSCS WERE DIFFERENTIATED INTO FOREBRAIN CORTI...      1  \n",
      "2                                    CONTROL NEURONS      1  \n",
      "3                                    CONTROL NEURONS      1  \n",
      "4                                    CONTROL NEURONS      1  \u001b[0m\u001b[32;1m\u001b[1;3mHere is the summary of the rows based on the specified columns:\n",
      "\n",
      "| characteristics_ch1                                   | extract_protocol_ch1                                                                                               | title                    | source_name_ch1                                                                                        | count |\n",
      "|------------------------------------------------------|-------------------------------------------------------------------------------------------------------------------|-------------------------|-------------------------------------------------------------------------------------------------------|-------|\n",
      "| CELL TYPE: FOREBRAIN CORTICAL NEURONS,AGENT: TOPOTECAN | RNA WAS EXTRACTED USING TRIZOL REAGENT.,SRANDED LIBRARIES WERE CONSTRUCTED WITH ILLUMINA KITS FOR STRANDED RNASEQ. | TOPOTECAN_RNASEQ [HUMAN] | IPSCS WERE DIFFERENTIATED INTO FOREBRAIN CORTICAL NEURONS AND TREATED WITH 10ÂΜM TOPOTECAN FOR 6 DAYS. | 1     |\n",
      "| CELL TYPE: FOREBRAIN CORTICAL NEURONS,AGENT: VEHICLE   | RNA WAS EXTRACTED USING TRIZOL REAGENT.,SRANDED LIBRARIES WERE CONSTRUCTED WITH ILLUMINA KITS FOR STRANDED RNASEQ. | VEHICLE_RNASEQ [HUMAN]   | IPSCS WERE DIFFERENTIATED INTO FOREBRAIN CORTICAL NEURONS AND TREATED WITH VEHICLE FOR 6 DAYS.         | 1     |\n",
      "| SAMPLE GROUP: CONTROL,TISSUE: 14 DAY NEURONS           | RNA-SEQ WAS CARRIED OUT ON AND DAY 14 NEURONS AT THE COLUMBIA GENOME CENTER. TOTAL RNA WAS ISOLATED FROM CELLS USING THE MIRNEASY KIT (QIAGEN) ACCORDING TO THE MANUFACTURERÂS PROTOCOL. AN ADDITIONAL DNASE1 DIGESTION STEP WAS PERFORMED TO ENSURE THAT THE SAMPLES WERE NOT CONTAMINATED WITH GENOMIC DNA. RNA PURITY WAS ASSESSED USING THE AGILANT 2100 BIOANALYZER (BEIJING GENOMICS INSTITUTE). EACH RNA SAMPLE HAD AN A260:A280 RATIO ABOVE 1.8, A RIN>9, AND A A260:A230 RATIO ABOVE 2.2.,BRIEFLY, TOTAL RNA WAS CONVERTED TO CDNA USING OLIGO DT, WHICH WAS THEN USED FOR ILLUMINA SEQUENCING LIBRARY PREPARATION. | IPSC2                    | CONTROL NEURONS                                                                                        | 1     |\n",
      "| SAMPLE GROUP: CONTROL,TISSUE: 14 DAY NEURONS           | RNA-SEQ WAS CARRIED OUT ON AND DAY 14 NEURONS AT THE COLUMBIA GENOME CENTER. TOTAL RNA WAS ISOLATED FROM CELLS USING THE MIRNEASY KIT (QIAGEN) ACCORDING TO THE MANUFACTURERÂS PROTOCOL. AN ADDITIONAL DNASE1 DIGESTION STEP WAS PERFORMED TO ENSURE THAT THE SAMPLES WERE NOT CONTAMINATED WITH GENOMIC DNA. RNA PURITY WAS ASSESSED USING THE AGILANT 2100 BIOANALYZER (BEIJING GENOMICS INSTITUTE). EACH RNA SAMPLE HAD AN A260:A280 RATIO ABOVE 1.8, A RIN>9, AND A A260:A230 RATIO ABOVE 2.2.,BRIEFLY, TOTAL RNA WAS CONVERTED TO CDNA USING OLIGO DT, WHICH WAS THEN USED FOR ILLUMINA SEQUENCING LIBRARY PREPARATION. | IPSC5                    | CONTROL NEURONS                                                                                        | 1     |\n",
      "| SAMPLE GROUP: CONTROL,TISSUE: 14 DAY NEURONS           | RNA-SEQ WAS CARRIED OUT ON AND DAY 14 NEURONS AT THE COLUMBIA GENOME CENTER. TOTAL RNA WAS ISOLATED FROM CELLS USING THE MIRNEASY KIT (QIAGEN) ACCORDING TO THE MANUFACTURERÂS PROTOCOL. AN ADDITIONAL DNASE1 DIGESTION STEP WAS PERFORMED TO ENSURE THAT THE SAMPLES WERE NOT CONTAMINATED WITH GENOMIC DNA. RNA PURITY WAS ASSESSED USING THE AGILANT 2100 BIOANALYZER (BEIJING GENOMICS INSTITUTE). EACH RNA SAMPLE HAD AN A260:A280 RATIO ABOVE 1.8, A RIN>9, AND A A260:A230 RATIO ABOVE 2.2.,BRIEFLY, TOTAL RNA WAS CONVERTED TO CDNA USING OLIGO DT, WHICH WAS THEN USED FOR ILLUMINA SEQUENCING LIBRARY PREPARATION. | IPSC6                    | CONTROL NEURONS                                                                                        | 1     |\n",
      "\n",
      "Each unique combination of the specified columns is listed along with the count of occurrences.\u001b[0m\n",
      "\n",
      "\u001b[1m> Finished chain.\u001b[0m\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "{'input': 'Please summarize the rows based on the values in the columns titles \"characteristics_ch1\", \"extract_protocol_ch1\", \"title\", and \"source_name_ch1\".',\n",
       " 'output': 'Here is the summary of the rows based on the specified columns:\\n\\n| characteristics_ch1                                   | extract_protocol_ch1                                                                                               | title                    | source_name_ch1                                                                                        | count |\\n|------------------------------------------------------|-------------------------------------------------------------------------------------------------------------------|-------------------------|-------------------------------------------------------------------------------------------------------|-------|\\n| CELL TYPE: FOREBRAIN CORTICAL NEURONS,AGENT: TOPOTECAN | RNA WAS EXTRACTED USING TRIZOL REAGENT.,SRANDED LIBRARIES WERE CONSTRUCTED WITH ILLUMINA KITS FOR STRANDED RNASEQ. | TOPOTECAN_RNASEQ [HUMAN] | IPSCS WERE DIFFERENTIATED INTO FOREBRAIN CORTICAL NEURONS AND TREATED WITH 10ÂΜM TOPOTECAN FOR 6 DAYS. | 1     |\\n| CELL TYPE: FOREBRAIN CORTICAL NEURONS,AGENT: VEHICLE   | RNA WAS EXTRACTED USING TRIZOL REAGENT.,SRANDED LIBRARIES WERE CONSTRUCTED WITH ILLUMINA KITS FOR STRANDED RNASEQ. | VEHICLE_RNASEQ [HUMAN]   | IPSCS WERE DIFFERENTIATED INTO FOREBRAIN CORTICAL NEURONS AND TREATED WITH VEHICLE FOR 6 DAYS.         | 1     |\\n| SAMPLE GROUP: CONTROL,TISSUE: 14 DAY NEURONS           | RNA-SEQ WAS CARRIED OUT ON AND DAY 14 NEURONS AT THE COLUMBIA GENOME CENTER. TOTAL RNA WAS ISOLATED FROM CELLS USING THE MIRNEASY KIT (QIAGEN) ACCORDING TO THE MANUFACTURERÂ\\x80\\x99S PROTOCOL. AN ADDITIONAL DNASE1 DIGESTION STEP WAS PERFORMED TO ENSURE THAT THE SAMPLES WERE NOT CONTAMINATED WITH GENOMIC DNA. RNA PURITY WAS ASSESSED USING THE AGILANT 2100 BIOANALYZER (BEIJING GENOMICS INSTITUTE). EACH RNA SAMPLE HAD AN A260:A280 RATIO ABOVE 1.8, A RIN>9, AND A A260:A230 RATIO ABOVE 2.2.,BRIEFLY, TOTAL RNA WAS CONVERTED TO CDNA USING OLIGO DT, WHICH WAS THEN USED FOR ILLUMINA SEQUENCING LIBRARY PREPARATION. | IPSC2                    | CONTROL NEURONS                                                                                        | 1     |\\n| SAMPLE GROUP: CONTROL,TISSUE: 14 DAY NEURONS           | RNA-SEQ WAS CARRIED OUT ON AND DAY 14 NEURONS AT THE COLUMBIA GENOME CENTER. TOTAL RNA WAS ISOLATED FROM CELLS USING THE MIRNEASY KIT (QIAGEN) ACCORDING TO THE MANUFACTURERÂ\\x80\\x99S PROTOCOL. AN ADDITIONAL DNASE1 DIGESTION STEP WAS PERFORMED TO ENSURE THAT THE SAMPLES WERE NOT CONTAMINATED WITH GENOMIC DNA. RNA PURITY WAS ASSESSED USING THE AGILANT 2100 BIOANALYZER (BEIJING GENOMICS INSTITUTE). EACH RNA SAMPLE HAD AN A260:A280 RATIO ABOVE 1.8, A RIN>9, AND A A260:A230 RATIO ABOVE 2.2.,BRIEFLY, TOTAL RNA WAS CONVERTED TO CDNA USING OLIGO DT, WHICH WAS THEN USED FOR ILLUMINA SEQUENCING LIBRARY PREPARATION. | IPSC5                    | CONTROL NEURONS                                                                                        | 1     |\\n| SAMPLE GROUP: CONTROL,TISSUE: 14 DAY NEURONS           | RNA-SEQ WAS CARRIED OUT ON AND DAY 14 NEURONS AT THE COLUMBIA GENOME CENTER. TOTAL RNA WAS ISOLATED FROM CELLS USING THE MIRNEASY KIT (QIAGEN) ACCORDING TO THE MANUFACTURERÂ\\x80\\x99S PROTOCOL. AN ADDITIONAL DNASE1 DIGESTION STEP WAS PERFORMED TO ENSURE THAT THE SAMPLES WERE NOT CONTAMINATED WITH GENOMIC DNA. RNA PURITY WAS ASSESSED USING THE AGILANT 2100 BIOANALYZER (BEIJING GENOMICS INSTITUTE). EACH RNA SAMPLE HAD AN A260:A280 RATIO ABOVE 1.8, A RIN>9, AND A A260:A230 RATIO ABOVE 2.2.,BRIEFLY, TOTAL RNA WAS CONVERTED TO CDNA USING OLIGO DT, WHICH WAS THEN USED FOR ILLUMINA SEQUENCING LIBRARY PREPARATION. | IPSC6                    | CONTROL NEURONS                                                                                        | 1     |\\n\\nEach unique combination of the specified columns is listed along with the count of occurrences.'}"
      ]
     },
     "execution_count": 63,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\n",
    "# Step 1: Read the table data into a DataFrame\n",
    "test_df = test1['meta']\n",
    "\n",
    "from langchain.agents.agent_types import AgentType\n",
    "from langchain_experimental.agents.agent_toolkits import create_pandas_dataframe_agent\n",
    "from langchain_openai import ChatOpenAI\n",
    "\n",
    "from langchain_openai import OpenAI\n",
    "\n",
    "agent = create_pandas_dataframe_agent(\n",
    "    ChatOpenAI(temperature=0, model=\"gpt-4o-mini\",openai_api_key=OPENAI_API_KEY),\n",
    "    test_df,\n",
    "    verbose=True,\n",
    "    agent_type=AgentType.OPENAI_FUNCTIONS,\n",
    "    allow_dangerous_code=True\n",
    ")\n",
    "\n",
    "agent.invoke(\"how many rows are there?\")\n",
    "\n",
    "agent.invoke(\"What are the main properties of the data?\")\n",
    "\n",
    "agent.invoke('Please summarize the rows based on the values in the columns titles \"characteristics_ch1\", \"extract_protocol_ch1\", \"title\", and \"source_name_ch1\".')\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "\u001b[1m> Entering new AgentExecutor chain...\u001b[0m\n",
      "\u001b[32;1m\u001b[1;3m\n",
      "Invoking: `python_repl_ast` with `{'query': 'df.info()'}`\n",
      "\n",
      "\n",
      "\u001b[0m\u001b[36;1m\u001b[1;3m<class 'pandas.core.frame.DataFrame'>\n",
      "Index: 5 entries, GSM1132425 to GSM1179928\n",
      "Data columns (total 6 columns):\n",
      " #   Column                Non-Null Count  Dtype \n",
      "---  ------                --------------  ----- \n",
      " 0   geo_accession         5 non-null      object\n",
      " 1   series_id             5 non-null      object\n",
      " 2   characteristics_ch1   5 non-null      object\n",
      " 3   extract_protocol_ch1  5 non-null      object\n",
      " 4   source_name_ch1       5 non-null      object\n",
      " 5   title                 5 non-null      object\n",
      "dtypes: object(6)\n",
      "memory usage: 280.0+ bytes\n",
      "\u001b[0m\u001b[32;1m\u001b[1;3mThe main properties of the data are as follows:\n",
      "\n",
      "- The dataframe has 5 entries (rows).\n",
      "- There are 6 columns in the dataframe: `geo_accession`, `series_id`, `characteristics_ch1`, `extract_protocol_ch1`, `source_name_ch1`, and `title`.\n",
      "- All columns have non-null values for all entries, meaning there are no missing values in this dataset.\n",
      "- The data type for all columns is `object`, indicating that they contain text or mixed data types.\n",
      "- The memory usage of the dataframe is approximately 280.0+ bytes.\u001b[0m\n",
      "\n",
      "\u001b[1m> Finished chain.\u001b[0m\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "{'input': 'What are the main properties of the data?',\n",
       " 'output': 'The main properties of the data are as follows:\\n\\n- The dataframe has 5 entries (rows).\\n- There are 6 columns in the dataframe: `geo_accession`, `series_id`, `characteristics_ch1`, `extract_protocol_ch1`, `source_name_ch1`, and `title`.\\n- All columns have non-null values for all entries, meaning there are no missing values in this dataset.\\n- The data type for all columns is `object`, indicating that they contain text or mixed data types.\\n- The memory usage of the dataframe is approximately 280.0+ bytes.'}"
      ]
     },
     "execution_count": 61,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "\u001b[1m> Entering new AgentExecutor chain...\u001b[0m\n",
      "\u001b[32;1m\u001b[1;3m\n",
      "Invoking: `python_repl_ast` with `{'query': \"# Group the dataframe by the specified columns and count the occurrences of each group\\ngrouped_summary = df.groupby(['characteristics_ch1', 'extract_protocol_ch1', 'title', 'source_name_ch1']).size().reset_index(name='counts')\\ngrouped_summary\"}`\n",
      "\n",
      "\n",
      "\u001b[0m\u001b[36;1m\u001b[1;3m                                 characteristics_ch1  \\\n",
      "0  CELL TYPE: FOREBRAIN CORTICAL NEURONS,AGENT: T...   \n",
      "1  CELL TYPE: FOREBRAIN CORTICAL NEURONS,AGENT: V...   \n",
      "2       SAMPLE GROUP: CONTROL,TISSUE: 14 DAY NEURONS   \n",
      "3       SAMPLE GROUP: CONTROL,TISSUE: 14 DAY NEURONS   \n",
      "4       SAMPLE GROUP: CONTROL,TISSUE: 14 DAY NEURONS   \n",
      "\n",
      "                                extract_protocol_ch1  \\\n",
      "0  RNA WAS EXTRACTED USING TRIZOL REAGENT.,SRANDE...   \n",
      "1  RNA WAS EXTRACTED USING TRIZOL REAGENT.,SRANDE...   \n",
      "2  RNA-SEQ WAS CARRIED OUT ON AND DAY 14 NEURONS ...   \n",
      "3  RNA-SEQ WAS CARRIED OUT ON AND DAY 14 NEURONS ...   \n",
      "4  RNA-SEQ WAS CARRIED OUT ON AND DAY 14 NEURONS ...   \n",
      "\n",
      "                      title  \\\n",
      "0  TOPOTECAN_RNASEQ [HUMAN]   \n",
      "1    VEHICLE_RNASEQ [HUMAN]   \n",
      "2                     IPSC2   \n",
      "3                     IPSC5   \n",
      "4                     IPSC6   \n",
      "\n",
      "                                     source_name_ch1  counts  \n",
      "0  IPSCS WERE DIFFERENTIATED INTO FOREBRAIN CORTI...       1  \n",
      "1  IPSCS WERE DIFFERENTIATED INTO FOREBRAIN CORTI...       1  \n",
      "2                                    CONTROL NEURONS       1  \n",
      "3                                    CONTROL NEURONS       1  \n",
      "4                                    CONTROL NEURONS       1  \u001b[0m\u001b[32;1m\u001b[1;3mHere is the summary of the rows based on the values in the columns \"characteristics_ch1\", \"extract_protocol_ch1\", \"title\", and \"source_name_ch1\":\n",
      "\n",
      "1. **Characteristics**: CELL TYPE: FOREBRAIN CORTICAL NEURONS, AGENT: TOPOTECAN\n",
      "   - **Extract Protocol**: RNA was extracted using TRIzol reagent. Stranded libraries were constructed with Illumina kits for stranded RNAseq.\n",
      "   - **Title**: TOPOTECAN_RNASEQ [HUMAN]\n",
      "   - **Source Name**: iPSCs were differentiated into forebrain cortical neurons and treated with 10μM topotecan for 6 days.\n",
      "   - **Count**: 1\n",
      "\n",
      "2. **Characteristics**: CELL TYPE: FOREBRAIN CORTICAL NEURONS, AGENT: VEHICLE\n",
      "   - **Extract Protocol**: RNA was extracted using TRIzol reagent. Stranded libraries were constructed with Illumina kits for stranded RNAseq.\n",
      "   - **Title**: VEHICLE_RNASEQ [HUMAN]\n",
      "   - **Source Name**: iPSCs were differentiated into forebrain cortical neurons and treated with vehicle for 6 days.\n",
      "   - **Count**: 1\n",
      "\n",
      "3. **Characteristics**: SAMPLE GROUP: CONTROL, TISSUE: 14 DAY NEURONS\n",
      "   - **Extract Protocol**: RNA-seq was carried out on and day 14 neurons at the Columbia Genome Center. Total RNA was isolated from cells using the miRNeasy kit (Qiagen) according to the manufacturer’s protocol. An additional DNase1 digestion step was performed to ensure that the samples were not contaminated with genomic DNA. RNA purity was assessed using the Agilent 2100 Bioanalyzer (Beijing Genomics Institute). Each RNA sample had an A260:A280 ratio above 1.8, a RIN>9, and a A260:A230 ratio above 2.2. Briefly, total RNA was converted to cDNA using oligo dT, which was then used for Illumina sequencing library preparation.\n",
      "   - **Title**: IPSC2\n",
      "   - **Source Name**: CONTROL NEURONS\n",
      "   - **Count**: 1\n",
      "\n",
      "4. **Characteristics**: SAMPLE GROUP: CONTROL, TISSUE: 14 DAY NEURONS\n",
      "   - **Extract Protocol**: Same as above.\n",
      "   - **Title**: IPSC5\n",
      "   - **Source Name**: CONTROL NEURONS\n",
      "   - **Count**: 1\n",
      "\n",
      "5. **Characteristics**: SAMPLE GROUP: CONTROL, TISSUE: 14 DAY NEURONS\n",
      "   - **Extract Protocol**: Same as above.\n",
      "   - **Title**: IPSC6\n",
      "   - **Source Name**: CONTROL NEURONS\n",
      "   - **Count**: 1\n",
      "\n",
      "Each unique combination of these columns appears only once in the dataset.\u001b[0m\n",
      "\n",
      "\u001b[1m> Finished chain.\u001b[0m\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "{'input': 'Please summarize the rows based on the values in the columns titles \"characteristics_ch1\", \"extract_protocol_ch1\", \"title\", and \"source_name_ch1\".',\n",
       " 'output': 'Here is the summary of the rows based on the values in the columns \"characteristics_ch1\", \"extract_protocol_ch1\", \"title\", and \"source_name_ch1\":\\n\\n1. **Characteristics**: CELL TYPE: FOREBRAIN CORTICAL NEURONS, AGENT: TOPOTECAN\\n   - **Extract Protocol**: RNA was extracted using TRIzol reagent. Stranded libraries were constructed with Illumina kits for stranded RNAseq.\\n   - **Title**: TOPOTECAN_RNASEQ [HUMAN]\\n   - **Source Name**: iPSCs were differentiated into forebrain cortical neurons and treated with 10μM topotecan for 6 days.\\n   - **Count**: 1\\n\\n2. **Characteristics**: CELL TYPE: FOREBRAIN CORTICAL NEURONS, AGENT: VEHICLE\\n   - **Extract Protocol**: RNA was extracted using TRIzol reagent. Stranded libraries were constructed with Illumina kits for stranded RNAseq.\\n   - **Title**: VEHICLE_RNASEQ [HUMAN]\\n   - **Source Name**: iPSCs were differentiated into forebrain cortical neurons and treated with vehicle for 6 days.\\n   - **Count**: 1\\n\\n3. **Characteristics**: SAMPLE GROUP: CONTROL, TISSUE: 14 DAY NEURONS\\n   - **Extract Protocol**: RNA-seq was carried out on and day 14 neurons at the Columbia Genome Center. Total RNA was isolated from cells using the miRNeasy kit (Qiagen) according to the manufacturer’s protocol. An additional DNase1 digestion step was performed to ensure that the samples were not contaminated with genomic DNA. RNA purity was assessed using the Agilent 2100 Bioanalyzer (Beijing Genomics Institute). Each RNA sample had an A260:A280 ratio above 1.8, a RIN>9, and a A260:A230 ratio above 2.2. Briefly, total RNA was converted to cDNA using oligo dT, which was then used for Illumina sequencing library preparation.\\n   - **Title**: IPSC2\\n   - **Source Name**: CONTROL NEURONS\\n   - **Count**: 1\\n\\n4. **Characteristics**: SAMPLE GROUP: CONTROL, TISSUE: 14 DAY NEURONS\\n   - **Extract Protocol**: Same as above.\\n   - **Title**: IPSC5\\n   - **Source Name**: CONTROL NEURONS\\n   - **Count**: 1\\n\\n5. **Characteristics**: SAMPLE GROUP: CONTROL, TISSUE: 14 DAY NEURONS\\n   - **Extract Protocol**: Same as above.\\n   - **Title**: IPSC6\\n   - **Source Name**: CONTROL NEURONS\\n   - **Count**: 1\\n\\nEach unique combination of these columns appears only once in the dataset.'}"
      ]
     },
     "execution_count": 62,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "nodes must be a list of Node objects.",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[30], line 10\u001b[0m\n\u001b[0;32m      6\u001b[0m Settings\u001b[38;5;241m.\u001b[39membed_model \u001b[38;5;241m=\u001b[39m OpenAIEmbedding(model\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mtext-embedding-ada-002\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[0;32m      8\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mllama_index\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mcore\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m SummaryIndex, VectorStoreIndex\n\u001b[1;32m---> 10\u001b[0m summary_index \u001b[38;5;241m=\u001b[39m \u001b[43mSummaryIndex\u001b[49m\u001b[43m(\u001b[49m\u001b[43mnodes\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m     11\u001b[0m vector_index \u001b[38;5;241m=\u001b[39m VectorStoreIndex(nodes)\n\u001b[0;32m     13\u001b[0m summary_query_engine \u001b[38;5;241m=\u001b[39m summary_index\u001b[38;5;241m.\u001b[39mas_query_engine(\n\u001b[0;32m     14\u001b[0m     response_mode\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mtree_summarize\u001b[39m\u001b[38;5;124m\"\u001b[39m,\n\u001b[0;32m     15\u001b[0m     use_async\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m,\n\u001b[0;32m     16\u001b[0m )\n",
      "File \u001b[1;32me:\\Projects\\RAG Test V0\\rag-env\\Lib\\site-packages\\llama_index\\core\\indices\\list\\base.py:58\u001b[0m, in \u001b[0;36mSummaryIndex.__init__\u001b[1;34m(self, nodes, objects, index_struct, show_progress, **kwargs)\u001b[0m\n\u001b[0;32m     49\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m__init__\u001b[39m(\n\u001b[0;32m     50\u001b[0m     \u001b[38;5;28mself\u001b[39m,\n\u001b[0;32m     51\u001b[0m     nodes: Optional[Sequence[BaseNode]] \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m,\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m     55\u001b[0m     \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs: Any,\n\u001b[0;32m     56\u001b[0m ) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[0;32m     57\u001b[0m \u001b[38;5;250m    \u001b[39m\u001b[38;5;124;03m\"\"\"Initialize params.\"\"\"\u001b[39;00m\n\u001b[1;32m---> 58\u001b[0m     \u001b[38;5;28;43msuper\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[38;5;21;43m__init__\u001b[39;49m\u001b[43m(\u001b[49m\n\u001b[0;32m     59\u001b[0m \u001b[43m        \u001b[49m\u001b[43mnodes\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mnodes\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m     60\u001b[0m \u001b[43m        \u001b[49m\u001b[43mindex_struct\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mindex_struct\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m     61\u001b[0m \u001b[43m        \u001b[49m\u001b[43mshow_progress\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mshow_progress\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m     62\u001b[0m \u001b[43m        \u001b[49m\u001b[43mobjects\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mobjects\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m     63\u001b[0m \u001b[43m        \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m     64\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32me:\\Projects\\RAG Test V0\\rag-env\\Lib\\site-packages\\llama_index\\core\\indices\\base.py:60\u001b[0m, in \u001b[0;36mBaseIndex.__init__\u001b[1;34m(self, nodes, objects, index_struct, storage_context, callback_manager, transformations, show_progress, **kwargs)\u001b[0m\n\u001b[0;32m     54\u001b[0m         \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\n\u001b[0;32m     55\u001b[0m             \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mThe constructor now takes in a list of Node objects. \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m     56\u001b[0m             \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mSince you are passing in a list of Document objects, \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m     57\u001b[0m             \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mplease use `from_documents` instead.\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m     58\u001b[0m         )\n\u001b[0;32m     59\u001b[0m     \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m---> 60\u001b[0m         \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mnodes must be a list of Node objects.\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[0;32m     62\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_storage_context \u001b[38;5;241m=\u001b[39m storage_context \u001b[38;5;129;01mor\u001b[39;00m StorageContext\u001b[38;5;241m.\u001b[39mfrom_defaults()\n\u001b[0;32m     63\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_docstore \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_storage_context\u001b[38;5;241m.\u001b[39mdocstore\n",
      "\u001b[1;31mValueError\u001b[0m: nodes must be a list of Node objects."
     ]
    }
   ],
   "source": [
    "\n",
    "\n",
    "from llama_index.core import Settings\n",
    "from llama_index.llms.openai import OpenAI\n",
    "from llama_index.embeddings.openai import OpenAIEmbedding\n",
    "\n",
    "Settings.llm = OpenAI(model=\"gpt-3.5-turbo\")\n",
    "Settings.embed_model = OpenAIEmbedding(model=\"text-embedding-ada-002\")\n",
    "\n",
    "from llama_index.core import SummaryIndex, VectorStoreIndex\n",
    "\n",
    "summary_index = SummaryIndex(nodes)\n",
    "vector_index = VectorStoreIndex(nodes)\n",
    "\n",
    "summary_query_engine = summary_index.as_query_engine(\n",
    "    response_mode=\"tree_summarize\",\n",
    "    use_async=True,\n",
    ")\n",
    "vector_query_engine = vector_index.as_query_engine()\n",
    "\n",
    "from llama_index.core.tools import QueryEngineTool\n",
    "\n",
    "\n",
    "summary_tool = QueryEngineTool.from_defaults(\n",
    "    query_engine=summary_query_engine,\n",
    "    description=(\n",
    "        \"Useful for summarization questions related to test\"\n",
    "    ),\n",
    ")\n",
    "\n",
    "vector_tool = QueryEngineTool.from_defaults(\n",
    "    query_engine=vector_query_engine,\n",
    "    description=(\n",
    "        \"Useful for retrieving specific context from the test data.\"\n",
    "    ),\n",
    ")\n",
    "\n",
    "## Report on available data for the user query and propose next steps\n",
    "\n",
    "# Use the available data to train a RAG agent\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "rag-env",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
