{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "import json\n",
    "import os\n",
    "import re\n",
    "import archs4py\n",
    "import nest_asyncio\n",
    "\n",
    "archive_file = \"human_gene_v2.5.h5\"\n",
    "\n",
    "nest_asyncio.apply()\n",
    "\n",
    "def get_config_data():\n",
    "    with open(\"local_data.json\") as json_file:\n",
    "        data = json.load(json_file)\n",
    "        return data[\"OPENAI_KEY\"][\"key\"]\n",
    "        \n",
    "OPENAI_API_KEY = get_config_data()\n",
    "\n",
    "os.environ[\"OPENAI_API_KEY\"] = OPENAI_API_KEY\n",
    "\n",
    "#from llama_index.core import (\n",
    "#    SimpleDirectoryReader,\n",
    "#    VectorStoreIndex,\n",
    "#    StorageContext,\n",
    "#    load_index_from_storage,\n",
    "#)\n",
    "from llama_index.llms.openai import OpenAI\n",
    "\n",
    "#llm = OpenAI(model=\"gpt-4o-mini\")\n",
    "\n",
    "from llama_index.core import Settings\n",
    "from llama_index.llms.openai import OpenAI\n",
    "from llama_index.embeddings.openai import OpenAIEmbedding\n",
    "\n",
    "# Use ollama in JSON mode\n",
    "Settings.llm = OpenAI(\n",
    "    model=\"gpt-4o-mini\"\n",
    ")\n",
    "Settings.embed_model = OpenAIEmbedding(model_name=\"text-embedding-3-small\")\n",
    "\n",
    "###\n",
    "\n",
    "def get_archs4py_expression_counts(query, file):\n",
    "\n",
    "    \"\"\"\n",
    "    Accepts a parsed user query and filters the dataset using archs4py.\n",
    "    \n",
    "    Parameters:\n",
    "    - query: str, the user query\n",
    "    - file: the loaded dataset\n",
    "    \n",
    "    Returns:\n",
    "    - temp_data: a subset of the dataset relevant to the query that consists of a list of data objects (e.g. meta and RNAseq data)\n",
    "    \"\"\"\n",
    "    try:\n",
    "        temp_data = archs4py.data.samples(file, query)\n",
    "        return temp_data\n",
    "\n",
    "    except Exception as e:\n",
    "        return f\"Error retrieving data: {str(e)}\"\n",
    "\n",
    "\n",
    "#global meta_file_counter\n",
    "#meta_file_counter = 0\n",
    "#global counts_file_counter \n",
    "#counts_file_counter = 0\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "#test = updated_archs4py_query(\"Look up gene expression for GSM1132425, GSM1132426, GSM1132427, GSM1179927, and GSM1179928\")\n",
    "#print(test['meta'].shape)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Define tools\n",
    "from llama_index.core.tools import QueryEngineTool, ToolMetadata\n",
    "from llama_index.core.agent import ReActAgent\n",
    "import pandas as pd\n",
    "from llama_index.experimental.query_engine import PandasQueryEngine\n",
    "from llama_index.core import SimpleDirectoryReader\n",
    "\n",
    "\n",
    "# Tool to accept user input to retrieve data from GEO using existing functions and ARCHS4PY\n",
    "from llama_index.core.tools import FunctionTool\n",
    "from pydantic import Field\n",
    "\n",
    "\n",
    "def get_weather(\n",
    "    location: str = Field(\n",
    "        description=\"A city name and state, formatted like '<name>, <state>'\"\n",
    "    ),\n",
    ") -> str:\n",
    "    \"\"\"Useful for getting the weather for a given location.\"\"\"\n",
    "    return f\"The weather in {location} is sunny.\"\n",
    "\n",
    "\n",
    "def get_time(\n",
    "    location: str = Field(\n",
    "        description=\"A city name and state, formatted like '<name>, <state>'\"\n",
    "    ),\n",
    ") -> str:\n",
    "    \"\"\"Useful for getting the current time for a given location.\"\"\"\n",
    "    return f\"The current time in {location} is 12:00 PM.\"\n",
    "\n",
    "def test_parse_archs4py_query(\n",
    "    full_query: str = Field(\n",
    "        description=\"A query for GEO datasets\"\n",
    "    ),\n",
    ") -> str:\n",
    "    \"\"\"Useful for retrieving datasets from GEO and saving them locally. Once a dataset is saved, this tool shouldn't be used again without confirmation from the user.\"\"\"\n",
    "\n",
    "    try:\n",
    "    # Convert the query to uppercase to ensure case-insensitive matching\n",
    "        archive_file = \"human_gene_v2.5.h5\"\n",
    "        directory = \"./testing_data\"\n",
    "        if \"GSM\" in full_query:\n",
    "            query_upper = full_query.upper()\n",
    "            # Perform operation for queries containing \"GSM\"\n",
    "            # Split the string into a list of elements using spaces as the separator\n",
    "            temp_elements = query_upper.split()\n",
    "            pattern = r'[^a-zA-Z0-9]'\n",
    "            # Use a list comprehension to apply the regex substitution to each string\n",
    "            temp_elements = [re.sub(pattern, '', s) for s in temp_elements]\n",
    "        \n",
    "            # Filter the list to include only elements containing \"GSE\"\n",
    "            temp_search_query = [temp_element for temp_element in temp_elements if \"GSM\" in temp_element]\n",
    "            temp_meta = archs4py.meta.samples(archive_file, temp_search_query, \n",
    "                meta_fields=[\"geo_accession\", \"series_id\", \"characteristics_ch1\", \"extract_protocol_ch1\", \"source_name_ch1\", \"title\"])\n",
    "            query_dataset = pd.DataFrame(temp_meta)\n",
    "            #global meta_file_counter\n",
    "            #print(meta_file_counter)\n",
    "            #meta_file_counter += 1\n",
    "            file_path = os.path.join(directory, f\"temp_meta.csv\")\n",
    "            query_dataset.to_csv(file_path, index=False)\n",
    "            return f\"DataFrame saved successfully at {file_path}\"\n",
    "\n",
    "        elif \"GSE\" in full_query:\n",
    "            query_upper = full_query.upper()\n",
    "            # Perform operation for queries containing \"GSE\"\n",
    "            # Split the string into a list of elements using spaces as the separator\n",
    "            temp_elements = query_upper.split()\n",
    "            #temp_elements = remove_non_alphanumeric(temp_elements)\n",
    "            pattern = r'[^a-zA-Z0-9]'\n",
    "            # Use a list comprehension to apply the regex substitution to each string\n",
    "            temp_elements = [re.sub(pattern, '', s) for s in temp_elements]\n",
    "        \n",
    "            # Filter the list to include only elements containing \"GSE\"\n",
    "            temp_search_query = [temp_element for temp_element in temp_elements if \"GSE\" in temp_element]\n",
    "\n",
    "            if len(temp_search_query) > 1:\n",
    "                prior_dataset = []\n",
    "            for temp_index, temp_value in enumerate(temp_search_query):\n",
    "                temp_meta = archs4py.meta.series(archive_file, temp_value, \n",
    "                    meta_fields=[\"geo_accession\", \"series_id\", \"characteristics_ch1\", \"extract_protocol_ch1\", \"source_name_ch1\", \"title\"])\n",
    "                query_dataset = pd.DataFrame(temp_meta)\n",
    "                if temp_index > 0:\n",
    "                    query_dataset = pd.concat([prior_dataset, \n",
    "                                                    query_dataset], \n",
    "                                                    ignore_index=True)\n",
    "                if temp_index < len(temp_search_query) - 1:\n",
    "                    prior_dataset = query_dataset\n",
    "                if temp_index == len(temp_search_query) - 1:\n",
    "                    #global meta_file_counter\n",
    "                    #print(meta_file_counter)\n",
    "                    #meta_file_counter += 1\n",
    "                    file_path = os.path.join(directory, f\"temp_meta.csv\")\n",
    "                    query_dataset.to_csv(file_path, index=False)\n",
    "                    return f\"DataFrame saved successfully at {file_path}\"\n",
    "        else:\n",
    "            # Perform default operation for other queries\n",
    "            #pattern = r'\"[^\"]*\"|\\S+'\n",
    "    \n",
    "            # Find all matches in the text\n",
    "            #matches = re.findall(pattern, full_query)\n",
    "            #temp_search_query = [element for element in matches if element.startswith('\"') and element.endswith('\"')]\n",
    "            #temp_search_query = [element[1:-1] for element in temp_search_query]\n",
    "            temp_search_query = [full_query]\n",
    "            if len(temp_search_query) > 1:\n",
    "                prior_dataset = []\n",
    "            for temp_index, temp_value in enumerate(temp_search_query):\n",
    "                print(temp_value)\n",
    "                temp_meta = archs4py.meta.meta(archive_file, temp_value, \n",
    "                    meta_fields=[\"geo_accession\", \"series_id\", \"characteristics_ch1\", \"extract_protocol_ch1\", \"source_name_ch1\", \"title\"],\n",
    "                    remove_sc=True)\n",
    "                print(temp_meta.shape)\n",
    "                if temp_index > 0:\n",
    "                    temp_meta = temp_meta[temp_meta.index.isin(prior_dataset.index)]\n",
    "                if temp_index < len(temp_search_query) - 1:\n",
    "                    prior_dataset = temp_meta\n",
    "                if temp_index == len(temp_search_query) - 1:\n",
    "                    query_dataset = pd.DataFrame(temp_meta)\n",
    "                    #global meta_file_counter\n",
    "                    #print(meta_file_counter)\n",
    "                    #meta_file_counter += 1\n",
    "                    file_path = os.path.join(directory, f\"temp_meta.csv\")\n",
    "                    query_dataset.to_csv(file_path, index=False)\n",
    "                    return f\"DataFrame saved successfully at {file_path}\"\n",
    "    except Exception as e:\n",
    "        return f\"Error retrieving data: {str(e)}\"\n",
    "\n",
    "\n",
    "def create_metadata_query_engine(\n",
    "    query_dataset: str = Field(\n",
    "        description=\"A tool to load locally saved dataframes from csv files\"\n",
    "    ),\n",
    ") -> str:\n",
    "    \"\"\"Useful for retrieving datasets from GEO and saving them locally.\"\"\"\n",
    "    try:\n",
    "        directory = \"./testing_data\"\n",
    "        file_path = os.path.join(directory, f\"temp_meta.csv\")\n",
    "        SimpleDirectoryReader(input_files=[file_path])\n",
    "        query_dataset = pd.read_csv(file_path)\n",
    "        return PandasQueryEngine(df=query_dataset, verbose=True, synthesize_response=True)\n",
    "    except Exception as e:\n",
    "        return f\"Error retrieving data: {str(e)}\"\n",
    "\n",
    "\n",
    "metadata_query_tool = QueryEngineTool(\n",
    "        query_engine=create_metadata_query_engine(),\n",
    "        metadata=ToolMetadata(\n",
    "            name=\"GEO_metadata\",\n",
    "            description=(\n",
    "                \"Provides information about GEO_metadata for the selected dataset. \"\n",
    "                \"The tool should load metadata that is downloaded from GEO and saved locally.\"\n",
    "            ),\n",
    "        ),\n",
    "    )\n",
    "archs4py_tool = FunctionTool.from_defaults(test_parse_archs4py_query, name=\"use_archs4py\", description=\"Useful for retrieving gene expression datasets from GEO.\")\n",
    "weather_tool = FunctionTool.from_defaults(get_weather, name=\"get_weather\", description=\"Useful for getting the weather for a given location.\")\n",
    "time_tool = FunctionTool.from_defaults(get_time, name=\"get_time\", description=\"Useful for getting the current time for a given location.\")\n",
    "all_tools = [weather_tool, time_tool,archs4py_tool,metadata_query_tool]\n",
    "#all_tools = [weather_tool, time_tool,archs4py_tool]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 6/6 [00:05<00:00,  1.19it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(24663, 6)\n"
     ]
    }
   ],
   "source": [
    "temp_meta = archs4py.meta.meta(archive_file, \"iPSC\", \n",
    "                    meta_fields=[\"geo_accession\", \"series_id\", \"characteristics_ch1\", \"extract_protocol_ch1\", \"source_name_ch1\", \"title\"], \n",
    "                    remove_sc=True)\n",
    "print(temp_meta.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Added user message to memory: Look up gene expression for the terms IPSC\n",
      "INFO:httpx:HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "=== Calling Function ===\n",
      "Calling function: use_archs4py with args: {\"full_query\":\"IPSC\"}\n",
      "IPSC\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 6/6 [00:05<00:00,  1.15it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(24663, 6)\n",
      "Got output: DataFrame saved successfully at ./testing_data\\temp_meta.csv\n",
      "========================\n",
      "\n",
      "INFO:httpx:HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      ">> Task marked as finished by the agent, executing task execution.\n",
      "Agent: I have retrieved the gene expression data related to the term \"IPSC.\" The data has been saved successfully. If you need further analysis or specific information from this dataset, please let me know!\n",
      "Added user message to memory: Please summarize the table that was saved locally by describing broad groups of samples by their descriptions\n",
      "INFO:httpx:HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "=== Calling Function ===\n",
      "Calling function: GEO_metadata with args: {\"input\":\"./testing_data/temp_meta.csv\"}\n",
      "INFO:httpx:HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "> Pandas Instructions:\n",
      "```\n",
      "df.to_csv('./testing_data/temp_meta.csv', index=False)\n",
      "```\n",
      "> Pandas Output: None\n",
      "INFO:httpx:HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "Got output: It seems that the query is related to a CSV file located at `./testing_data/temp_meta.csv`. However, the output indicates that there is no data or result to display from this file. If you need assistance with the contents of the CSV or any specific operations to perform on it, please provide more details!\n",
      "========================\n",
      "\n",
      "INFO:httpx:HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      ">> Task marked as finished by the agent, executing task execution.\n",
      "Agent: It seems that I cannot directly access the contents of the CSV file saved locally. However, you can open the file and provide me with the relevant details or a summary of the data it contains. Once you share that information, I can help you analyze or summarize it further.\n"
     ]
    }
   ],
   "source": [
    "#Look up gene expression for GSM1132425, GSM1132426, GSM1132427, GSM1179927, and GSM1179928\n",
    "#Look up gene expression for the terms IPSC\n",
    "\n",
    "## Create human in the loop agent with tools\n",
    "\n",
    "#meta_file_counter = 0\n",
    "#counts_file_counter = 0\n",
    "\n",
    "from llama_index.core.agent import AgentRunner, ReActAgent\n",
    "from llama_index.agent.openai import OpenAIAgentWorker, OpenAIAgent\n",
    "from llama_index.agent.openai import OpenAIAgentWorker\n",
    "\n",
    "\n",
    "agent_llm = OpenAI(model=\"gpt-4o-mini\",timeout=120)\n",
    "# agent_llm = OpenAI(model=\"gpt-4-1106-preview\")\n",
    "\n",
    "#agent = ReActAgent.from_tools(\n",
    "#    all_tools, llm=agent_llm, verbose=True, max_iterations=20,\n",
    "#)\n",
    "\n",
    "agent = OpenAIAgent.from_tools(\n",
    "    all_tools, llm=agent_llm, verbose=True, max_iterations=20,\n",
    ")\n",
    "\n",
    "def chat_repl(exit_when_done: bool = True):\n",
    "    \"\"\"Chat REPL.\n",
    "\n",
    "    Args:\n",
    "        exit_when_done(bool): if True, automatically exit when step is finished.\n",
    "            Set to False if you want to keep going even if step is marked as finished by the agent.\n",
    "            If False, you need to explicitly call \"exit\" to finalize a task execution.\n",
    "\n",
    "    \"\"\"\n",
    "    task_message = None\n",
    "    while task_message != \"exit\":\n",
    "        task_message = input(\">> Human: \")\n",
    "        if task_message == \"exit\":\n",
    "            break\n",
    "\n",
    "        task = agent.create_task(task_message)\n",
    "\n",
    "        response = None\n",
    "        step_output = None\n",
    "        message = None\n",
    "        while message != \"exit\":\n",
    "            if message is None or message == \"\":\n",
    "                step_output = agent.run_step(task.task_id)\n",
    "            else:\n",
    "                step_output = agent.run_step(task.task_id, input=message)\n",
    "            if exit_when_done and step_output.is_last:\n",
    "                print(\n",
    "                    \">> Task marked as finished by the agent, executing task execution.\"\n",
    "                )\n",
    "                break\n",
    "\n",
    "            message = input(\n",
    "                \">> Add feedback during step? (press enter/leave blank to continue, and type 'exit' to stop): \"\n",
    "            )\n",
    "            if message == \"exit\":\n",
    "                break\n",
    "\n",
    "        if step_output is None:\n",
    "            print(\">> You haven't run the agent. Task is discarded.\")\n",
    "        elif not step_output.is_last:\n",
    "            print(\">> The agent hasn't finished yet. Task is discarded.\")\n",
    "        else:\n",
    "            response = agent.finalize_response(task.task_id)\n",
    "        print(f\"Agent: {str(response)}\")\n",
    "\n",
    "\n",
    "## Test agent\n",
    "chat_repl()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(636, 6)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>geo_accession</th>\n",
       "      <th>series_id</th>\n",
       "      <th>characteristics_ch1</th>\n",
       "      <th>extract_protocol_ch1</th>\n",
       "      <th>source_name_ch1</th>\n",
       "      <th>title</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>GSM1556306</td>\n",
       "      <td>GSE63734,GSE80163</td>\n",
       "      <td>DIAGNOSIS: SCHIZOPHRENIA,GENDER: MALE,REPOSITO...</td>\n",
       "      <td>CELLS WERE LYSED IN RNA BEE (TEL-TEST, INC). R...</td>\n",
       "      <td>HIPSC FOREBRAIN NEURONS</td>\n",
       "      <td>SZ1_A</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>GSM1556307</td>\n",
       "      <td>GSE63734,GSE80163</td>\n",
       "      <td>DIAGNOSIS: SCHIZOPHRENIA,GENDER: MALE,REPOSITO...</td>\n",
       "      <td>CELLS WERE LYSED IN RNA BEE (TEL-TEST, INC). R...</td>\n",
       "      <td>HIPSC FOREBRAIN NEURONS</td>\n",
       "      <td>SZ1_B</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>GSM1556308</td>\n",
       "      <td>GSE63734,GSE80163</td>\n",
       "      <td>DIAGNOSIS: SCHIZOPHRENIA,GENDER: MALE,REPOSITO...</td>\n",
       "      <td>CELLS WERE LYSED IN RNA BEE (TEL-TEST, INC). R...</td>\n",
       "      <td>HIPSC FOREBRAIN NEURONS</td>\n",
       "      <td>SZ2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>GSM1556309</td>\n",
       "      <td>GSE63734,GSE80163</td>\n",
       "      <td>DIAGNOSIS: SCHIZOPHRENIA,GENDER: FEMALE,REPOSI...</td>\n",
       "      <td>CELLS WERE LYSED IN RNA BEE (TEL-TEST, INC). R...</td>\n",
       "      <td>HIPSC FOREBRAIN NEURONS</td>\n",
       "      <td>SZ3_3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>GSM1556310</td>\n",
       "      <td>GSE63734,GSE80163</td>\n",
       "      <td>DIAGNOSIS: SCHIZOPHRENIA,GENDER: FEMALE,REPOSI...</td>\n",
       "      <td>CELLS WERE LYSED IN RNA BEE (TEL-TEST, INC). R...</td>\n",
       "      <td>HIPSC FOREBRAIN NEURONS</td>\n",
       "      <td>SZ3_5</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  geo_accession          series_id  \\\n",
       "0    GSM1556306  GSE63734,GSE80163   \n",
       "1    GSM1556307  GSE63734,GSE80163   \n",
       "2    GSM1556308  GSE63734,GSE80163   \n",
       "3    GSM1556309  GSE63734,GSE80163   \n",
       "4    GSM1556310  GSE63734,GSE80163   \n",
       "\n",
       "                                 characteristics_ch1  \\\n",
       "0  DIAGNOSIS: SCHIZOPHRENIA,GENDER: MALE,REPOSITO...   \n",
       "1  DIAGNOSIS: SCHIZOPHRENIA,GENDER: MALE,REPOSITO...   \n",
       "2  DIAGNOSIS: SCHIZOPHRENIA,GENDER: MALE,REPOSITO...   \n",
       "3  DIAGNOSIS: SCHIZOPHRENIA,GENDER: FEMALE,REPOSI...   \n",
       "4  DIAGNOSIS: SCHIZOPHRENIA,GENDER: FEMALE,REPOSI...   \n",
       "\n",
       "                                extract_protocol_ch1          source_name_ch1  \\\n",
       "0  CELLS WERE LYSED IN RNA BEE (TEL-TEST, INC). R...  HIPSC FOREBRAIN NEURONS   \n",
       "1  CELLS WERE LYSED IN RNA BEE (TEL-TEST, INC). R...  HIPSC FOREBRAIN NEURONS   \n",
       "2  CELLS WERE LYSED IN RNA BEE (TEL-TEST, INC). R...  HIPSC FOREBRAIN NEURONS   \n",
       "3  CELLS WERE LYSED IN RNA BEE (TEL-TEST, INC). R...  HIPSC FOREBRAIN NEURONS   \n",
       "4  CELLS WERE LYSED IN RNA BEE (TEL-TEST, INC). R...  HIPSC FOREBRAIN NEURONS   \n",
       "\n",
       "   title  \n",
       "0  SZ1_A  \n",
       "1  SZ1_B  \n",
       "2    SZ2  \n",
       "3  SZ3_3  \n",
       "4  SZ3_5  "
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test = pd.read_csv(\"./testing_data/temp_meta.csv\")\n",
    "print(test.shape)\n",
    "test.head()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "rag-env",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
